# Отчет: Сравнительный анализ производительности REST и gRPC API

## 1. Описание тестируемого приложения

### Архитектура

Два идентичных по функционалу API для управления глоссарием терминов блокчейна:
- **REST API**: FastAPI с JSON-сериализацией
- **gRPC API**: FastAPI с Protocol Buffers

### Используемые технологии

- Framework: FastAPI
- База данных: Neo4j (графовая БД)
- Протоколы: HTTP/1.1 + JSON (REST), HTTP/2 + Protobuf (gRPC)
- Язык: Python

### Эндпоинты/Методы

1. `GET /api/terms` / `GetAllTerms()` - получение списка всех терминов
2. `GET /api/terms/{term}` / `GetTerm(keyword)` - получение конкретного термина
3. `POST /api/terms` / `CreateTerm(keyword, definition)` - создание нового термина
4. `GET /api/graph` / `GetGraph()` - получение графа связей

### Возвращаемые данные

- Список терминов: массив объектов с полями name, definition, related_terms
- Отдельный термин: объект с детальной информацией
- Граф: JSON/Protobuf представление связей между терминами
- Размер ответа: от 152 байт (single term) до 222 КБ (full graph)

### Данные для POST запроса
```json
{
  "keyword": "string",
  "definition": "string",
  "category": "string",
  "source": "string"
}
```

---

## 2. Настройки тестовой среды

### 2.1 Аппаратные ресурсы

**Сервер приложений:**
- CPU: 8 vCPU
- RAM: 32 GB
- Диск: 850 GB SSD
- ОС: Ubuntu 22.04
- Хостинг: dzhevelik.com

**Клиент нагрузки:**
- ОС: Windows
- Локальная машина

### 2.2 Архитектура стенда
```
┌─────────────────────────────────────┐
│   Сервер: dzhevelik.com             │
│   8 vCPU / 32GB RAM / Ubuntu 22.04  │
│                                     │
│   ┌─────────────┐  ┌─────────────┐ │
│   │  REST API   │  │  gRPC API   │ │
│   │  FastAPI    │  │  FastAPI    │ │
│   └──────┬──────┘  └──────┬──────┘ │
│          │                │        │
│          └────────┬───────┘        │
│                   │                │
│            ┌──────▼──────┐         │
│            │   Neo4j     │         │
│            │  (Graph DB) │         │
│            └─────────────┘         │
└─────────────────────────────────────┘
                  ▲
                  │ HTTPS/gRPC SSL
                  │ (через интернет)
         ┌────────┴────────┐
         │  Locust Client  │
         │ (local machine) │
         └─────────────────┘
```

**Компоненты:**
- REST API: https://vkr.dzhevelik.com
- gRPC API: grpc.dzhevelik.com:443 (SSL)
- Neo4j: внутренний порт на сервере
- Locust: локальная машина Windows

### 2.3 Версии ПО

- Locust: 2.43.1
- Python (клиент): 3.11.2
- Сервер: Ubuntu 22.04
- FastAPI, Neo4j: стандартные версии на сервере

### 2.4 Дополнительные инструменты

Дополнительные инструменты мониторинга не использовались. Метрики собирались исключительно средствами Locust.

---

## 3. Тестовые сценарии

### 3.1 Описание сценариев

#### 3.1.1 Легкая нагрузка (Light Load)

**Конфигурация:**
- Пользователи: 10
- Spawn rate: 1 user/sec
- Длительность: 30s

**Команды запуска:**
```bash
locust -f rest_locustfile.py --headless -u 10 -r 1 -t 30s --html results/rest_light.html
locust -f grpc_locustfile.py --headless -u 10 -r 1 -t 30s --html results/grpc_light.html
```

**Логика поведения:**
- Смешанная нагрузка на все эндпоинты
- Случайный выбор операций (read/write)
- Паузы 1-3 секунды между запросами

**Гипотеза:**
gRPC покажет преимущество за счет бинарной сериализации и HTTP/2

#### 3.1.2 Рабочая нагрузка (Normal Load)

**Конфигурация:**
- Пользователи: 50
- Spawn rate: 5 users/sec
- Длительность: 60s

**Команды запуска:**
```bash
locust -f rest_locustfile.py --headless -u 50 -r 5 -t 60s --html results/rest_normal.html
locust -f grpc_locustfile.py --headless -u 50 -r 5 -t 60s --html results/grpc_normal.html
```

**Логика поведения:**
- Имитация реального использования
- Преобладание read операций (83%)
- Реалистичные паузы между запросами

**Гипотеза:**
Разница в производительности станет заметнее при росте нагрузки

#### 3.1.3 Тест на стабильность (Stability Test)

**Конфигурация:**
- Пользователи: 50
- Spawn rate: 5 users/sec
- Длительность: 120s

**Команды запуска:**
```bash
locust -f rest_locustfile.py --headless -u 50 -r 5 -t 120s --html results/rest_stability.html
locust -f grpc_locustfile.py --headless -u 50 -r 5 -t 120s --html results/grpc_stability.html
```

**Логика поведения:**
- Длительная работа под нагрузкой
- Проверка деградации производительности
- Выявление утечек памяти или проблем со стабильностью

**Гипотеза:**
Оба протокола должны сохранить стабильность без значительной деградации

#### 3.1.4 Стресс-тест (Stress Test)

**Конфигурация:**
- Пользователи: 100
- Spawn rate: 10 users/sec
- Длительность: 60s

**Команды запуска:**
```bash
locust -f rest_locustfile.py --headless -u 100 -r 10 -t 60s --html results/rest_stress.html
locust -f grpc_locustfile.py --headless -u 100 -r 10 -t 60s --html results/grpc_stress.html
```

**Логика поведения:**
- Максимальная нагрузка
- Поиск точки деградации
- Выявление пределов производительности

**Гипотеза:**
Будут выявлены различия в пределах производительности каждого протокола

### 3.2 Фрагменты кода Locust

#### REST API

**Конфигурация пользователя:**
```python
class GlossaryRESTUser(HttpUser):
    host = "https://vkr.dzhevelik.com"
    wait_time = between(1, 3)
```

**Пример задач с пропорциями:**
```python
@task(10)  # 55% запросов
def get_all_terms(self):
    self.client.get("/api/terms")

@task(5)   # 28% запросов
def get_single_term(self):
    keyword = random.choice(self.terms).get("keyword")
    self.client.get(f"/api/terms/{keyword}")

@task(2)   # 11% запросов
def create_term(self):
    payload = {
        "keyword": f"LoadTest{random.randint(1000, 9999)}",
        "definition": "Тестовый термин",
        "category": "Test"
    }
    self.client.post("/api/terms", json=payload)

@task(1)   # 6% запросов
def get_graph(self):
    self.client.get("/api/graph")
```

#### gRPC API

**Конфигурация клиента:**
```python
class GrpcClient:
    def __init__(self, host):
        credentials = grpc.ssl_channel_credentials()
        self.channel = grpc.secure_channel('grpc.dzhevelik.com:443', credentials)
        self.stub = glossary_pb2_grpc.GlossaryServiceStub(self.channel)
```

**Пример метода с измерением времени:**
```python
def get_all_terms(self):
    start_time = time.time()
    try:
        response = self.stub.GetAllTerms(glossary_pb2.Empty())
        total_time = int((time.time() - start_time) * 1000)
        return True, total_time, len(response.terms)
    except grpc.RpcError as e:
        total_time = int((time.time() - start_time) * 1000)
        return False, total_time, str(e)
```

**Пропорции задач:** идентичны REST (10:5:2:1)

**Полный код:** см. `locust_tests/rest_locustfile.py` и `locust_tests/grpc_locustfile.py`

---

## 4. Результаты тестирования

### 4.1 Основные метрики

#### Таблица 1: Легкая нагрузка (10 users, 30s)

| Метрика | REST | gRPC |
|---------|------|------|
| RPS | 4.32 | 4.51 |
| Avg Response Time | 116 ms | 108 ms |
| p50 | 98 ms | 94 ms |
| p95 | 300 ms | 290 ms |
| p99 | 400 ms | 330 ms |
| Failures | 0% | 0% |
| Total Requests | 126 | 135 |

#### Таблица 2: Рабочая нагрузка (50 users, 60s)

| Метрика | REST | gRPC |
|---------|------|------|
| RPS | 21.21 | 7.97 |
| Avg Response Time | 125 ms | 124 ms |
| p50 | 120 ms | 97 ms |
| p95 | 290 ms | 320 ms |
| p99 | 420 ms | 400 ms |
| Failures | 0% | 0% |
| Total Requests | 1267 | 528 |

#### Таблица 3: Тест на стабильность (50 users, 120s)

| Метрика | REST | gRPC |
|---------|------|------|
| RPS | 22.11 | 7.47 |
| Avg Response Time | 181 ms | 133 ms |
| p50 | 200 ms | 130 ms |
| p95 | 390 ms | 350 ms |
| p99 | 510 ms | 410 ms |
| Failures | 0% | 0% |
| Total Requests | 2637 | 919 |

#### Таблица 4: Стресс-тест (100 users, 60s)

| Метрика | REST | gRPC |
|---------|------|------|
| RPS | 42.74 | 5.27 |
| Avg Response Time | 166 ms | 189 ms |
| p50 | 180 ms | 130 ms |
| p95 | 380 ms | 430 ms |
| p99 | 480 ms | 720 ms |
| Failures | 0% | 0% |
| Total Requests | 2536 | 404 |

### 4.2 Анализ результатов

#### Деградация производительности

**Начало деградации:**
- **REST**: деградация не наблюдается в рамках тестов. RPS растет линейно с увеличением нагрузки (4.32 → 21.21 → 42.74)
- **gRPC**: деградация начинается при 50+ пользователях. RPS падает с 7.97 до 5.27 при стрессе

**Точка деградации:**
- **REST**: не достигнута (продолжает масштабироваться)
- **gRPC**: при 50-100 одновременных пользователях

#### Латентность при росте нагрузки

**REST:**
- Среднее время остается стабильным: 116-181 ms
- p95 растет умеренно: 300 → 390 ms
- p99 увеличивается до 510 ms при длительной нагрузке
- При стрессе латентность улучшается: 166 ms (большая пропускная способность)

**gRPC:**
- Среднее время: 108-189 ms
- p95 относительно стабильно: 290-430 ms
- p99 резко деградирует при стрессе: 330 → 720 ms
- Медиана (p50) остается стабильной: 94-130 ms

#### Бутылочное горлышко

**REST:**
- Отсутствие видимых узких мест
- Линейная масштабируемость
- Вероятно, оптимизированная работа с connection pooling

**gRPC:**
- Деградация при высокой нагрузке указывает на ограничения
- Возможные причины:
  - Настройки HTTP/2 (max concurrent streams, window size)
  - Thread pool configuration
  - Overhead управления множественными стримами

#### Отличия результатов REST и gRPC

**При легкой нагрузке (10 users):**
- gRPC незначительно быстрее: 108 ms vs 116 ms
- Throughput практически равен: 4.51 vs 4.32 RPS

**При средней/высокой нагрузке (50-100 users):**
- REST показывает кратное превосходство в RPS: 21-42 vs 5-8
- REST обрабатывает в 3-8 раз больше запросов
- gRPC показывает лучшую медианную латентность, но худший p99

---

## 5. Сравнение REST и gRPC

### 5.1 Пропускная способность (RPS)

| Сценарий | REST RPS | gRPC RPS | Соотношение |
|----------|----------|----------|-------------|
| Light | 4.32 | 4.51 | gRPC выше на 4% |
| Normal | 21.21 | 7.97 | REST выше в 2.7 раза |
| Stability | 22.11 | 7.47 | REST выше в 3.0 раза |
| Stress | 42.74 | 5.27 | REST выше в 8.1 раза |

**Вывод:** REST демонстрирует превосходную масштабируемость под нагрузкой.

### 5.2 Латентность

| Сценарий | REST Avg | gRPC Avg | REST p99 | gRPC p99 |
|----------|----------|----------|----------|----------|
| Light | 116 ms | 108 ms | 400 ms | 330 ms |
| Normal | 125 ms | 124 ms | 420 ms | 400 ms |
| Stability | 181 ms | 133 ms | 510 ms | 410 ms |
| Stress | 166 ms | 189 ms | 480 ms | 720 ms |

**Вывод:** При легкой нагрузке gRPC быстрее, при высокой - REST стабильнее.

### 5.3 Анализ overhead

**REST (HTTP/1.1 + JSON):**
- Больший размер сообщений (текстовая сериализация)
- Overhead JSON parsing
- Но: лучшая производительность под нагрузкой в данной реализации
- Более эффективное использование ресурсов при масштабировании

**gRPC (HTTP/2 + Protobuf):**
- Меньший размер сообщений (бинарная сериализация)
- Overhead HTTP/2 multiplexing
- Преимущества не реализовались при высокой нагрузке
- Возможные причины: конфигурация, особенности реализации

### 5.4 Выводы по применимости

**REST рекомендуется для:**
- Систем с высокой и непредсказуемой нагрузкой (50+ RPS)
- Приложений, требующих горизонтального масштабирования
- Публичных API
- Случаев, когда важна пропускная способность
- Продакшн-систем с пиковыми нагрузками

**gRPC рекомендуется для:**
- Внутренних микросервисов с низкой/средней нагрузкой (<10 users)
- Случаев, где критична минимальная латентность при малой нагрузке
- Системы с потоковой передачей данных (streaming)
- Строго типизированных контрактов между сервисами
- После оптимизации конфигурации HTTP/2

---

## 6. Заключение

### Основные выводы

1. **При легкой нагрузке** (до 10 пользователей) gRPC показывает небольшое преимущество в латентности (108 ms vs 116 ms) и throughput (4.51 vs 4.32 RPS). Теоретические преимущества бинарной сериализации проявляются.

2. **При средней и высокой нагрузке** REST демонстрирует кратное превосходство в пропускной способности:
   - 50 пользователей: REST 21.21 RPS vs gRPC 7.97 RPS (в 2.7 раза)
   - 100 пользователей: REST 42.74 RPS vs gRPC 5.27 RPS (в 8.1 раза)

3. **Стабильность**: оба протокола показали 0% ошибок во всех сценариях, что подтверждает надежность реализации.

4. **Масштабируемость**: REST демонстрирует линейный рост производительности, gRPC — деградацию при увеличении нагрузки. Это указывает на необходимость оптимизации gRPC для высоконагруженных систем.

5. **Латентность**: gRPC показывает лучшую медианную латентность (p50), но худший p99 при стрессе (720 ms vs 480 ms), что критично для user experience.

### Рекомендации по оптимизации

**Для REST:**
- Внедрить connection pooling для Neo4j (если еще не реализовано)
- Добавить кеширование для часто запрашиваемых терминов (Redis/Memcached)
- Оптимизировать сериализацию JSON (использовать orjson/ujson)
- Рассмотреть CDN для статического контента

**Для gRPC:**
- Исследовать и настроить параметры HTTP/2:
  - `SETTINGS_MAX_CONCURRENT_STREAMS`
  - `SETTINGS_INITIAL_WINDOW_SIZE`
  - `SETTINGS_MAX_FRAME_SIZE`
- Проверить конфигурацию thread pool и executor
- Оптимизировать размеры batching для операций
- Профилировать код для выявления узких мест
- Рассмотреть использование connection pooling

**Общие:**
- Добавить мониторинг ресурсов (CPU, RAM, Network I/O)
- Настроить rate limiting для защиты от перегрузки
- Реализовать circuit breaker pattern
- Добавить метрики APM (Application Performance Monitoring)

### Возможные улучшения эксперимента

1. **Расширенное профилирование:**
   - Мониторинг CPU, RAM, network bandwidth во время тестов
   - Использование инструментов профилирования (py-spy, cProfile)
   - Анализ метрик Neo4j

2. **Дополнительные сценарии:**
   - Тесты с 200, 500, 1000 пользователей
   - Spike testing (резкий скачок нагрузки)
   - Soak testing (длительная работа 4-8 часов)

3. **Вариация payload:**
   - Тесты с маленькими (100 байт) vs большими (10 КБ) ответами
   - Анализ влияния размера данных на производительность

4. **Распределенная среда:**
   - Тестирование с географически распределенными клиентами
   - Добавление искусственной сетевой задержки (latency injection)

5. **Сравнение версий:**
   - Тестирование разных версий протоколов
   - A/B тестирование различных конфигураций

### Ограничения проведенного тестирования

1. **Инфраструктурные:**
   - Тесты проводились на одном сервере (может быть специфичные оптимизации)
   - Отсутствие репликации/шардирования БД
   - Клиент и сервер в разных сетях (влияние интернет-соединения)

2. **Метрики:**
   - Не измерялись аппаратные метрики (CPU, RAM, network utilization)
   - Отсутствие данных о состоянии Neo4j во время тестов
   - Нет информации о garbage collection

3. **Сценарии:**
   - Не тестировалась производительность при значительных сетевых задержках
   - Отсутствие тестов на очень длительную работу (hours/days)
   - Не проверялось поведение при частичных отказах системы
   - Не тестировались edge cases (очень большие запросы, множественные соединения)

4. **Окружение:**
   - Возможное влияние других процессов на сервере
   - Нестабильность интернет-соединения
   - Отсутствие изоляции тестовой среды

5. **Методология:**
   - Паузы между запросами (1-3 сек) не отражают максимальную нагрузку
   - Ограниченный набор сценариев использования
   - Синтетическая нагрузка может отличаться от реальной

